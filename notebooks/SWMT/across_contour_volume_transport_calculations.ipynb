{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02f6fccb-7b65-4ad8-8420-b6e8d8f46209",
   "metadata": {},
   "source": [
    "# Compute cross contour transport from daily data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e5b3177-1b4b-4f33-ac23-1071816ef1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cosima_cookbook as cc\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from gsw import SA_from_SP, p_from_z, sigma0\n",
    "import argparse\n",
    "from dask.distributed import Client\n",
    "import logging\n",
    "logging.captureWarnings(True)\n",
    "logging.getLogger('py.warnings').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbf72385-45e7-4abc-be11-a6c460d1500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = cc.database.create_session()\n",
    "\n",
    "year = str(1992)\n",
    "time_step = 0\n",
    "\n",
    "expt = '01deg_jra55v140_iaf_cycle4_MWpert'\n",
    "\n",
    "start_time = year + '-01-01'\n",
    "end_time = year + '-12-31'\n",
    "\n",
    "# reference density value:\n",
    "rho_0 = 1025.0\n",
    "# range which matches the size of contour arrays\n",
    "lat_range_cont = slice(-90, -59)\n",
    "# range which matches output of meltwater exp\n",
    "lat_range = slice(-78.82-0.01, -59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eecdffab-9c38-4739-8742-02bd01c6d272",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Open grid cell width data for domain'''\n",
    "\n",
    "# some grid data is required, a little complicated because these variables\n",
    "# don't behave well with some\n",
    "dyt = cc.querying.getvar(expt, 'dyt', session, n=1)\n",
    "dxu = cc.querying.getvar(expt, 'dxu', session, n=1)\n",
    "\n",
    "# select latitude range:\n",
    "dxu = dxu.sel(yu_ocean=lat_range)\n",
    "dyt = dyt.sel(yt_ocean=lat_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f5d0cf4-b40b-45a0-8bc9-89f9dedda25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Open contour data'''\n",
    "isobath_depth = 1000\n",
    "outfile = (\n",
    "    '/g/data/v45/akm157/model_data/access-om2/Antarctic_slope_contour_' +\n",
    "    str(isobath_depth) + 'm.npz')\n",
    "data = np.load(outfile)\n",
    "mask_y_transport = data['mask_y_transport']\n",
    "mask_x_transport = data['mask_x_transport']\n",
    "mask_y_transport_numbered = data['mask_y_transport_numbered']\n",
    "mask_x_transport_numbered = data['mask_x_transport_numbered']\n",
    "\n",
    "yt_ocean = cc.querying.getvar(expt, 'yt_ocean', session, n=1)\n",
    "yt_ocean = yt_ocean.sel(yt_ocean=lat_range_cont)\n",
    "yu_ocean = cc.querying.getvar(expt, 'yu_ocean', session, n=1)\n",
    "yu_ocean = yu_ocean.sel(yu_ocean=lat_range_cont)\n",
    "xt_ocean = cc.querying.getvar(expt, 'xt_ocean', session, n=1)\n",
    "xu_ocean = cc.querying.getvar(expt, 'xu_ocean', session, n=1)\n",
    "\n",
    "# Convert contour masks to data arrays, so we can multiply them later.\n",
    "# We need to ensure the lat lon coordinates correspond to the actual data\n",
    "# location:\n",
    "#       The y masks are used for vhrho, so like vhrho this should have\n",
    "#       dimensions (yu_ocean, xt_ocean).\n",
    "#       The x masks are used for uhrho, so like uhrho this should have\n",
    "#       dimensions (yt_ocean, xu_ocean).\n",
    "#       However the actual name will always be simply y_ocean/x_ocean\n",
    "#       irrespective of the variable to make concatenation of transports\n",
    "#       in both direction and sorting possible.\n",
    "\n",
    "mask_x_transport = xr.DataArray(\n",
    "    mask_x_transport,\n",
    "    coords=[('y_ocean', yt_ocean.data), ('x_ocean', xu_ocean.data)])\n",
    "mask_y_transport = xr.DataArray(\n",
    "    mask_y_transport,\n",
    "    coords=[('y_ocean', yu_ocean.data), ('x_ocean', xt_ocean.data)])\n",
    "mask_x_transport_numbered = xr.DataArray(\n",
    "    mask_x_transport_numbered,\n",
    "    coords=[('y_ocean', yt_ocean.data), ('x_ocean', xu_ocean.data)])\n",
    "mask_y_transport_numbered = xr.DataArray(\n",
    "    mask_y_transport_numbered,\n",
    "    coords=[('y_ocean', yu_ocean.data), ('x_ocean', xt_ocean.data)])\n",
    "\n",
    "# number of points along contour:\n",
    "num_points = int(np.maximum(np.max(mask_y_transport_numbered),\n",
    "                 np.max(mask_x_transport_numbered)))\n",
    "\n",
    "# change lat range to match output of meltwater exp\n",
    "mask_x_transport = mask_x_transport.sel(y_ocean=lat_range)\n",
    "mask_y_transport = mask_y_transport.sel(y_ocean=lat_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "005e36aa-d9b1-4217-af68-ddcfaae34cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Stack contour data into 1D and extract lat/lon on contour'''\n",
    "# Create the contour order data-array. Note that in this procedure the\n",
    "# x-grid counts have x-grid dimensions and the y-grid counts have y-grid\n",
    "# dimensions, but these are implicit, the dimension *names* are kept\n",
    "# general across the counts, the generic y_ocean, x_ocean, so that\n",
    "# concatening works but we dont double up with numerous counts for one\n",
    "# lat/lon point.\n",
    "\n",
    "# stack contour data into 1d:\n",
    "mask_x_numbered_1d = mask_x_transport_numbered.stack(\n",
    "    contour_index=['y_ocean', 'x_ocean'])\n",
    "mask_x_numbered_1d = mask_x_numbered_1d.where(\n",
    "    mask_x_numbered_1d > 0, drop=True)\n",
    "mask_y_numbered_1d = mask_y_transport_numbered.stack(\n",
    "    contour_index=['y_ocean', 'x_ocean'])\n",
    "mask_y_numbered_1d = mask_y_numbered_1d.where(\n",
    "    mask_y_numbered_1d > 0, drop=True)\n",
    "contour_ordering = xr.concat((mask_x_numbered_1d, mask_y_numbered_1d),\n",
    "                             dim='contour_index')\n",
    "contour_ordering = contour_ordering.sortby(contour_ordering)\n",
    "\n",
    "# get lat and lon along contour, useful for plotting later:\n",
    "lat_along_contour = contour_ordering.y_ocean\n",
    "lon_along_contour = contour_ordering.x_ocean\n",
    "contour_index_array = np.arange(1, len(contour_ordering)+1)\n",
    "# don't need the multi-index anymore, replace with contour count and save\n",
    "lat_along_contour.coords['contour_index'] = contour_index_array\n",
    "lon_along_contour.coords['contour_index'] = contour_index_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b48afb00-8caa-4f15-b479-376a6ec5f85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Open uhrho, vhrho from daily data'''\n",
    "\n",
    "# Note vhrho_nt is v*dz*1035 and positioned on north centre edge of t-cell.\n",
    "vhrho = cc.querying.getvar(expt,  'vhrho_nt', session,\n",
    "                           start_time=start_time, end_time=end_time)\n",
    "uhrho = cc.querying.getvar(expt, 'uhrho_et', session,\n",
    "                           start_time=start_time, end_time=end_time)\n",
    "vhrho = vhrho.rename({'xt_ocean_sub01': 'xt_ocean', 'yt_ocean_sub01': 'yt_ocean'})\n",
    "uhrho = uhrho.rename({'xt_ocean_sub01': 'xt_ocean', 'yt_ocean_sub01': 'yt_ocean'})\n",
    "\n",
    "# select latitude range and this year:\n",
    "vhrho = vhrho.sel(yt_ocean=slice(vhrho.yt_ocean.min(), None)).isel(\n",
    "    yt_ocean=slice(None, -1)).sel(time=slice(start_time, end_time))\n",
    "uhrho = uhrho.sel(yt_ocean=slice(uhrho.yt_ocean.min(), None)).isel(\n",
    "    yt_ocean=slice(None, -1)).sel(time=slice(start_time, end_time))\n",
    "\n",
    "# Note that vhrho is defined as the transport across the northern edge of\n",
    "#       a tracer cell so its coordinates should be (yu_ocean, xt_ocean).\n",
    "#  uhrho is defined as the transport across the eastern edge of a tracer\n",
    "#       cell so its coordinates should be (yt_ocean, xu_ocean).\n",
    "#  However we will keep the actual name as simply y_ocean/x_ocean\n",
    "#       irrespective of the variable to make concatenation and sorting\n",
    "#       possible.\n",
    "yt_ocean = dyt.yt_ocean.values\n",
    "yu_ocean = dxu.yu_ocean.values\n",
    "xu_ocean = dxu.xu_ocean.values\n",
    "xt_ocean = dyt.xt_ocean.values\n",
    "vhrho.coords['yt_ocean'] = yu_ocean\n",
    "uhrho.coords['xt_ocean'] = xu_ocean\n",
    "vhrho = vhrho.rename({'yt_ocean': 'y_ocean', 'xt_ocean': 'x_ocean'})\n",
    "uhrho = uhrho.rename({'yt_ocean': 'y_ocean', 'xt_ocean': 'x_ocean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9191d04-4524-42dd-865d-3c0955508eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Convert to transports'''\n",
    "# First we also need to change coords on dxu, dyt, so we can multiply the\n",
    "# transports:\n",
    "dyt = dyt.reset_coords().dyt  # remove geolon_t/geolat_t coordinates\n",
    "dxu = dxu.reset_coords().dxu  # remove geolon_t/geolat_t coordinates\n",
    "dxu.coords['xu_ocean'] = xt_ocean\n",
    "dxu = dxu.rename({'yu_ocean': 'y_ocean', 'xu_ocean': 'x_ocean'})\n",
    "dyt.coords['xt_ocean'] = xu_ocean\n",
    "dyt = dyt.rename({'yt_ocean': 'y_ocean', 'xt_ocean': 'x_ocean'})\n",
    "\n",
    "# convert to transports and multiply by contour masks:\n",
    "vhrho = vhrho*dxu*mask_y_transport/rho_0\n",
    "uhrho = uhrho*dyt*mask_x_transport/rho_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "180f777c-19d3-407c-9af3-95778e6326a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Extract transport values along contour:'''\n",
    "# load one timestep of transport data:\n",
    "# loading here speeds it up by about 5x...\n",
    "uhrho_i = uhrho[time_step, ...]\n",
    "uhrho_i = uhrho_i.load()\n",
    "vhrho_i = vhrho[time_step, ...]\n",
    "vhrho_i = vhrho_i.load()\n",
    "\n",
    "# stack transports into 1d and drop any points not on contour:\n",
    "x_transport_1d_i = uhrho_i.stack(contour_index=['y_ocean', 'x_ocean'])\n",
    "x_transport_1d_i = x_transport_1d_i.where(\n",
    "    mask_x_numbered_1d > 0, drop=True)\n",
    "y_transport_1d_i = vhrho_i.stack(contour_index=['y_ocean', 'x_ocean'])\n",
    "y_transport_1d_i = y_transport_1d_i.where(\n",
    "    mask_y_numbered_1d > 0, drop=True)\n",
    "\n",
    "# combine all points on contour:\n",
    "vol_trans_across_contour = xr.concat((x_transport_1d_i, y_transport_1d_i),\n",
    "                                     dim='contour_index')\n",
    "vol_trans_across_contour = vol_trans_across_contour.sortby(\n",
    "    contour_ordering)\n",
    "vol_trans_across_contour.coords['contour_index'] = contour_index_array\n",
    "vol_trans_across_contour = vol_trans_across_contour.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afdd13db-609c-457a-88df-bf9a71bf7684",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Open salt data, interpolate onto transport grids, and extract along\n",
    "   contour'''\n",
    "salt = cc.querying.getvar(expt, 'salt', session, start_time=start_time,\n",
    "                          end_time=end_time, ncfile='%daily%')\n",
    "salt = salt.rename({'xt_ocean_sub01': 'xt_ocean', 'yt_ocean_sub01': 'yt_ocean'})\n",
    "\n",
    "# select latitude range and this year:\n",
    "salt = salt.sel(yt_ocean=slice(salt.yt_ocean.min(), None)).isel(\n",
    "    yt_ocean=slice(None, -1)).sel(time=slice(start_time, end_time))\n",
    "\n",
    "# This is faster if we load first here:\n",
    "salt_i = salt[time_step, ...]\n",
    "salt_i = salt_i.load()\n",
    "salt_i = salt_i.rename({'yt_ocean': 'y_ocean', 'xt_ocean': 'x_ocean'})\n",
    "\n",
    "# Note that this interpolation does not work as generically as e.g.\n",
    "# salt.interp(), but it is much faster and doesn't require removing\n",
    "# chunking (which also slow things down).\n",
    "# Be careful that your latitude range extends at least one point either\n",
    "# direction beyond your contour.\n",
    "# If your domain is not the full longitude range, you will need to adapt\n",
    "# this, so you have the correct interpolation only the edges of your domain\n",
    "# (it assumes it is reentrant).\n",
    "# Need to overwrite coords, so these two variables can be added together:\n",
    "salt_w = salt_i.copy()\n",
    "salt_w.coords['x_ocean'] = xu_ocean\n",
    "salt_e = salt_i.roll(x_ocean=-1)\n",
    "salt_e.coords['x_ocean'] = xu_ocean\n",
    "# salt_xgrid will be on the uhrho grid:\n",
    "salt_xgrid = (salt_e + salt_w)/2\n",
    "\n",
    "salt_s = salt_i.copy()\n",
    "salt_s.coords['y_ocean'] = yu_ocean\n",
    "salt_n = salt_i.roll(y_ocean=-1)\n",
    "salt_n.coords['y_ocean'] = yu_ocean\n",
    "# salt_ygrid will be on the vhrho grid:\n",
    "salt_ygrid = (salt_s + salt_n)/2\n",
    "\n",
    "# stack transports into 1d and drop any points not on contour:\n",
    "salt_xgrid = salt_xgrid.where(mask_x_transport_numbered > 0)\n",
    "salt_ygrid = salt_ygrid.where(mask_y_transport_numbered > 0)\n",
    "x_salt_1d = salt_xgrid.stack(contour_index=['y_ocean', 'x_ocean'])\n",
    "y_salt_1d = salt_ygrid.stack(contour_index=['y_ocean', 'x_ocean'])\n",
    "x_salt_1d = x_salt_1d.where(mask_x_numbered_1d > 0, drop=True)\n",
    "y_salt_1d = y_salt_1d.where(mask_y_numbered_1d > 0, drop=True)\n",
    "\n",
    "# combine all points on contour:\n",
    "salt_along_contour = xr.concat((x_salt_1d, y_salt_1d), dim='contour_index')\n",
    "salt_along_contour = salt_along_contour.sortby(contour_ordering)\n",
    "salt_along_contour.coords['contour_index'] = contour_index_array\n",
    "salt_along_contour = salt_along_contour.load()\n",
    "\n",
    "del (salt_i, salt_w, salt_e, salt_s, salt_n, salt_xgrid, salt_ygrid,\n",
    "     x_salt_1d, y_salt_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63ddb9d2-457f-4608-89c3-8dc672a35eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Open temp data, interpolate onto transport grids, and extract along\n",
    "   contour'''\n",
    "temp = cc.querying.getvar(expt, 'temp', session, start_time=start_time,\n",
    "                          end_time=end_time, ncfile='%daily%') - 273.15\n",
    "temp = temp.rename({'xt_ocean_sub01': 'xt_ocean', 'yt_ocean_sub01': 'yt_ocean'})\n",
    "\n",
    "# select latitude range and this year:\n",
    "temp = temp.sel(yt_ocean=slice(temp.yt_ocean.min(), None)).isel(\n",
    "    yt_ocean=slice(None, -1)).sel(time=slice(start_time, end_time))\n",
    "\n",
    "# This is faster if we load first here:\n",
    "temp_i = temp[time_step, ...]\n",
    "temp_i = temp_i.load()\n",
    "temp_i = temp_i.rename({'yt_ocean': 'y_ocean', 'xt_ocean': 'x_ocean'})\n",
    "\n",
    "# Note that this interpolation does not work as generically as e.g.\n",
    "# temp.interp(), but it is much faster and doesn't require removing\n",
    "# chunking (which also slow things down).\n",
    "# Be careful that your latitude range extends at least one point either\n",
    "# direction beyond your contour.\n",
    "# If your domain is not the full longitude range, you will need to adapt\n",
    "# this, so you have the correct interpolation only the edges of your domain\n",
    "# (it assumes it is reentrant).\n",
    "# Need to overwrite coords, so these two variables can be added together:\n",
    "temp_w = temp_i.copy()\n",
    "temp_w.coords['x_ocean'] = xu_ocean\n",
    "temp_e = temp_i.roll(x_ocean=-1)\n",
    "temp_e.coords['x_ocean'] = xu_ocean\n",
    "# temp_xgrid will be on the uhrho grid:\n",
    "temp_xgrid = (temp_e + temp_w)/2\n",
    "\n",
    "temp_s = temp_i.copy()\n",
    "temp_s.coords['y_ocean'] = yu_ocean\n",
    "temp_n = temp_i.roll(y_ocean=-1)\n",
    "temp_n.coords['y_ocean'] = yu_ocean\n",
    "# temp_ygrid will be on the vhrho grid:\n",
    "temp_ygrid = (temp_s + temp_n)/2\n",
    "\n",
    "# stack transports into 1d and drop any points not on contour:\n",
    "temp_xgrid = temp_xgrid.where(mask_x_transport_numbered > 0)\n",
    "temp_ygrid = temp_ygrid.where(mask_y_transport_numbered > 0)\n",
    "x_temp_1d = temp_xgrid.stack(contour_index=['y_ocean', 'x_ocean'])\n",
    "y_temp_1d = temp_ygrid.stack(contour_index=['y_ocean', 'x_ocean'])\n",
    "x_temp_1d = x_temp_1d.where(mask_x_numbered_1d > 0, drop=True)\n",
    "y_temp_1d = y_temp_1d.where(mask_y_numbered_1d > 0, drop=True)\n",
    "\n",
    "# combine all points on contour:\n",
    "temp_along_contour = xr.concat((x_temp_1d, y_temp_1d), dim='contour_index')\n",
    "temp_along_contour = temp_along_contour.sortby(contour_ordering)\n",
    "temp_along_contour.coords['contour_index'] = contour_index_array\n",
    "temp_along_contour = temp_along_contour.load()\n",
    "\n",
    "del (temp_i, temp_w, temp_e, temp_s, temp_n, temp_xgrid, temp_ygrid,\n",
    "     x_temp_1d, y_temp_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d040a8d-8f05-4f3f-92a8-6ec329662167",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Calculate density on contour'''\n",
    "st_ocean = vhrho.st_ocean.values\n",
    "depth = -st_ocean\n",
    "depth = xr.DataArray(depth, coords=[st_ocean], dims=['st_ocean'])\n",
    "depth_along_contour = (salt_along_contour*0+1)*depth\n",
    "\n",
    "pressure_along_contour = xr.DataArray(\n",
    "    p_from_z(depth_along_contour, lat_along_contour),\n",
    "    coords=[st_ocean, contour_index_array],\n",
    "    dims=['st_ocean', 'contour_index'],\n",
    "    name='pressure', attrs={'units': 'dbar'})\n",
    "\n",
    "# absolute salinity:\n",
    "abs_salt_along_contour = xr.DataArray(\n",
    "    SA_from_SP(salt_along_contour, pressure_along_contour,\n",
    "               lon_along_contour, lat_along_contour),\n",
    "    coords=[st_ocean, contour_index_array],\n",
    "    dims=['st_ocean', 'contour_index'],\n",
    "    name='Absolute salinity',\n",
    "    attrs={'units': 'Absolute Salinity (g/kg)'})\n",
    "\n",
    "sigma0_along_contour = xr.DataArray(\n",
    "    sigma0(abs_salt_along_contour, temp_along_contour),\n",
    "    coords=[st_ocean, contour_index_array],\n",
    "    dims=['st_ocean', 'contour_index'],\n",
    "    name='potential density ref 1000dbar',\n",
    "    attrs={'units': 'kg/m^3 (-1000 kg/m^3)'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ae5d551-5e96-4a6d-a821-ff0afd32bb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Bin into isopycnals'''\n",
    "# define isopycnal bins\n",
    "isopycnal_bins_sigma0 = np.arange(27.6, 28.11, 0.01)\n",
    "\n",
    "# intialise empty transport along contour in density bins array\n",
    "vol_trans_across_contour_binned = xr.DataArray(\n",
    "    np.zeros((len(isopycnal_bins_sigma0), len(contour_ordering))),\n",
    "    coords=[isopycnal_bins_sigma0, contour_index_array],\n",
    "    dims=['isopycnal_bins', 'contour_index'],\n",
    "    name='vol_trans_across_contour_binned')\n",
    "\n",
    "# loop through density bins:\n",
    "for i in range(len(isopycnal_bins_sigma0)-1):\n",
    "    bin_mask = sigma0_along_contour.where(\n",
    "        sigma0_along_contour <= isopycnal_bins_sigma0[i+1]).where(\n",
    "            sigma0_along_contour > isopycnal_bins_sigma0[i])*0+1\n",
    "    bin_fractions = (isopycnal_bins_sigma0[i+1]-sigma0_along_contour *\n",
    "                     bin_mask)/(isopycnal_bins_sigma0[i+1] -\n",
    "                                isopycnal_bins_sigma0[i])\n",
    "    # transport\n",
    "    transport_across_contour_in_sigmalower_bin = (\n",
    "        vol_trans_across_contour * bin_mask * bin_fractions).sum(\n",
    "        dim='st_ocean')\n",
    "    vol_trans_across_contour_binned[i, :] += (\n",
    "        transport_across_contour_in_sigmalower_bin.fillna(0))\n",
    "    del transport_across_contour_in_sigmalower_bin\n",
    "    transport_across_contour_in_sigmaupper_bin = (\n",
    "        vol_trans_across_contour * bin_mask * (1-bin_fractions)).sum(\n",
    "        dim='st_ocean')\n",
    "    vol_trans_across_contour_binned[i+1, :] += (\n",
    "        transport_across_contour_in_sigmaupper_bin.fillna(0))\n",
    "    del bin_mask, bin_fractions, transport_across_contour_in_sigmaupper_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "031b450e-c60b-453e-9ee8-fa8805aca0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Save'''\n",
    "path_output = '/g/data/e14/cs6673/meltwater/data_SWMT/'\n",
    "vol_trans_across_contour_binned = vol_trans_across_contour_binned.expand_dims(\n",
    "    time=[salt.time[time_step].values])\n",
    "ds_vol_trans_across_contour = xr.Dataset({'vol_transp_across_contour':\n",
    "                                          vol_trans_across_contour_binned})\n",
    "ds_vol_trans_across_contour.to_netcdf(\n",
    "    path_output + 'volume_transport_across_1000m_isobaths_' + expt + '_1d_' +\n",
    "    np.datetime_as_string(salt.time[time_step].values, unit='D') + '.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3-22.07]",
   "language": "python",
   "name": "conda-env-analysis3-22.07-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
